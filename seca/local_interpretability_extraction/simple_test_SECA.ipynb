{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-ncfL2BroQW",
        "outputId": "a76cae5b-6bde-4071-9138-44854a7bbb3a"
      },
      "outputs": [],
      "source": [
        "# !pip install saliency\n",
        "# !pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZJmYnLuzeN-",
        "outputId": "58898a12-9980-45f7-a46a-f062b5a0c23d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wjHbls0brHVX"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Maurits\\miniconda3\\envs\\seca\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from keras.applications.inception_v3 import preprocess_input as inception_preproc\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.color import rgba2rgb\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import saliency\n",
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V__zMoNU16Qu",
        "outputId": "b1a26580-fbcd-4b04-b3ad-6970836c4b35"
      },
      "outputs": [],
      "source": [
        "!pip list -v | grep saliency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images_dir = \"../example_data copy/test\"\n",
        "heatmap_dir = \"../../output\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxzSyLcZ3rpH"
      },
      "outputs": [],
      "source": [
        "from skimage import io\n",
        "\n",
        "from ..utils import load_image\n",
        "\n",
        "# def load_image(image_path):\n",
        "#     \"\"\"\n",
        "#         Loads specified image.\n",
        "#         Args:\n",
        "#             image_path (str): path to specific image in the dataset\n",
        "#     \"\"\"\n",
        "#     image = io.imread(image_path)\n",
        "#     return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_model(graph, weights: str = \"imagenet\"):\n",
        "    \"\"\"[summary]\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    weights : [type], optional\n",
        "        [description], by default \"imagenet\"\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    [type]\n",
        "        [description]\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    model = InceptionV3(weights='imagenet')\n",
        "    logits = graph.get_tensor_by_name('predictions/Softmax:0')\n",
        "    neuron_selector = tf.placeholder(tf.int32)  # Used to select the logit of the prediction\n",
        "    y = logits[0][neuron_selector]  # logit of prediction\n",
        "    prediction = tf.argmax(logits, 1)\n",
        "    images = graph.get_tensor_by_name('input_1:0') \n",
        "\n",
        "    return model, y, neuron_selector, prediction, images\n",
        "\n",
        "def verify_images(images_dir):\n",
        "    \"\"\"Verify images to be analysed\n",
        "\n",
        "    - Check file extensions\n",
        "    - Check size (not zero)\n",
        "    - Print names\n",
        "    \"\"\"\n",
        "    print(([name for name in os.listdir(images_dir)]))\n",
        "\n",
        "def upload_data_to_model(path_images: str, sample_size: int = None, target_size: tuple = (299, 299), batch_size: int = 1):\n",
        "    \"\"\"[summary]\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path_images : [type]\n",
        "        [description]\n",
        "    sample_size : [type], optional\n",
        "        [description], by default None\n",
        "    target_size : [type], optional\n",
        "        [description], by default (299, 299)\n",
        "    batch_size : [type], optional\n",
        "        [description], by default 1\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    [type]\n",
        "        [description]\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    ValueError\n",
        "        [description]\n",
        "    ValueError\n",
        "        [description]\n",
        "    \"\"\"\n",
        "    \n",
        "    test_datagen = ImageDataGenerator(preprocessing_function=inception_preproc)\n",
        "    test_generator = test_datagen.flow_from_directory(path_images, target_size=target_size, batch_size=batch_size, class_mode='categorical', shuffle=False)\n",
        "    \n",
        "    num_images = len(test_generator.filenames) if not sample_size else sample_size\n",
        "\n",
        "    if num_images > len(test_generator.filenames):\n",
        "        print(len(test_generator.filenames))\n",
        "        raise ValueError('The number of annotations cannot be higher than the number of available images.')\n",
        "    elif num_images == 0:\n",
        "        raise ValueError('The number of annotations needs to be greater than zero.')\n",
        "    \n",
        "    image_selection = np.random.choice(len(test_generator.filenames), num_images)\n",
        "    selected_images = np.array(test_generator.filenames)[image_selection]\n",
        "    \n",
        "    return selected_images\n",
        "\n",
        "def create_output_folder(path_heatmap, selected_images):\n",
        "    \"\"\"[summary]\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path_heatmap : [type]\n",
        "        [description]\n",
        "    selected_images : [type]\n",
        "        [description]\n",
        "    \"\"\"\n",
        "    if not os.path.exists(os.path.join(path_heatmap, selected_images[i].split('/')[0])):\n",
        "        os.makedirs(os.path.join(heatmap_dir, selected_images[i].split('/')[0]))\n",
        "    \n",
        "\n",
        "def run_model(image, prediction, stdev_spread=.05, nsamples=10):\n",
        "    \"\"\"[summary]\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : [type]\n",
        "        [description]\n",
        "    prediction : [type]\n",
        "        [description]\n",
        "    stdev_spread : [type], optional\n",
        "        [description], by default .05\n",
        "    nsamples : [type], optional\n",
        "        [description], by default 10\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    [type]\n",
        "        [description]\n",
        "    \"\"\"\n",
        "    \n",
        "    im = inception_preproc(image)\n",
        "    # Predict label\n",
        "    y_pred = sess.run(prediction, feed_dict={images: [im]})[0]\n",
        "    # Compute the vanilla mask and the smoothed mask.\n",
        "    smoothgrad_mask_3d = gradient_saliency.GetSmoothedMask(im, stdev_spread=stdev_spread, nsamples=nsamples, feed_dict={neuron_selector: y_pred})\n",
        "    # Call the visualization methods to convert the 3D tensors to 2D grayscale.\n",
        "    smoothgrad_mask_grayscale = saliency.tf1.VisualizeImageGrayscale(smoothgrad_mask_3d)\n",
        "\n",
        "    return smoothgrad_mask_grayscale\n",
        "\n",
        "def save_image(image, path_image):\n",
        "    \"\"\"[summary]\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : [type]\n",
        "        [description]\n",
        "    path_image : [type]\n",
        "        [description]\n",
        "    \"\"\"\n",
        "    # plt.imsave(os.path.normpath(os.path.join(heatmap_dir + selected_images[i])), image)\n",
        "    plt.imsave(path_image, image)\n",
        "\n",
        "def export_heatmap(image, path_image, colormap=\"inferno\"):\n",
        "    \"\"\"[summary]\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : [type]\n",
        "        [description]\n",
        "    path_image : [type]\n",
        "        [description]\n",
        "    colormap : [type], optional\n",
        "        [description], by default \"inferno\"\n",
        "    \"\"\"\n",
        "\n",
        "    cm = plt.get_cmap(colormap)\n",
        "    colored_heatmap = cm(smoothgrad_mask_grayscale)  # RGBA (A contains colormap) -> convert o RGB via rgba2rgb\n",
        "    image_overlay = 0.5 * (image/255) + 0.5 * rgba2rgb(colored_heatmap)  # img1*alpha + img2*(1-alpha)\n",
        "    # plt.imsave(os.path.normpath(os.path.join(heatmap_dir + selected_images[i][:-5] + '_heatmap' + selected_images[i][-5:])), image_overlay)\n",
        "    plt.imsave(path_image, image_overlay)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrtf-96osiLX",
        "outputId": "9025a385-018d-4618-dc37-48134632eab4"
      },
      "outputs": [],
      "source": [
        "\n",
        "sess = K.get_session()\n",
        "graph = sess.graph\n",
        "# images_dir = \"/content/drive/MyDrive/example_data/test\"\n",
        "# heatmap_dir = \"content/example_heatmaps/\"\n",
        "num_of_images = 3\n",
        "with graph.as_default():  # registers graph as default graph. Operations will be added to the graph\n",
        "        \n",
        "        # Set up ML model\n",
        "        # model = InceptionV3(weights='imagenet')\n",
        "        # logits = graph.get_tensor_by_name('predictions/Softmax:0')\n",
        "        # neuron_selector = tf.placeholder(tf.int32)  # Used to select the logit of the prediction\n",
        "        # y = logits[0][neuron_selector]  # logit of prediction\n",
        "        # prediction = tf.argmax(logits, 1)\n",
        "        \n",
        "        model, y, neuron_selector, prediction, images = setup_model(weigths='imagenet')\n",
        "\n",
        "        # Set up data format\n",
        "        # images = graph.get_tensor_by_name('input_1:0')        \n",
        "        # print(([name for name in os.listdir(images_dir)]))\n",
        "        verify_images()\n",
        "\n",
        "        # Upload data\n",
        "        # test_datagen = ImageDataGenerator(preprocessing_function=inception_preproc)\n",
        "        # test_generator = test_datagen.flow_from_directory(images_dir, target_size=(299, 299), batch_size=1, class_mode='categorical', shuffle=False)\n",
        "        # if num_of_images > len(test_generator.filenames):\n",
        "        #     print(len(test_generator.filenames))\n",
        "        #     raise ValueError('The number of annotations cannot be higher than the number of available images.')\n",
        "\n",
        "        # image_selection = np.random.choice(len(test_generator.filenames), num_of_images)\n",
        "        # selected_images = np.array(test_generator.filenames)[image_selection]\n",
        "\n",
        "        selected_images = upload_data_to_model(images_dir, num_of_images)\n",
        "\n",
        "        # Construct the saliency object.\n",
        "        gradient_saliency = saliency.tf1.GradientSaliency(graph, sess, y, images)\n",
        "        for i, img in enumerate(tqdm(selected_images)):\n",
        "            \n",
        "            # Create the folder if it does not exist\n",
        "            create_output_folder(heatmap_dir, selected_images)\n",
        "            # if not os.path.exists(os.path.join(heatmap_dir, selected_images[i].split('/')[0])):\n",
        "            #     os.makedirs(os.path.join(heatmap_dir, selected_images[i].split('/')[0]))\n",
        "                                    \n",
        "            # Skip if heatmap is already extracted\n",
        "            if os.path.exists(os.path.join(heatmap_dir, selected_images[i])):\n",
        "                continue\n",
        "\n",
        "            # Run model\n",
        "            image = load_image(os.path.join(images_dir, img))\n",
        "            \n",
        "            # im = inception_preproc(image)\n",
        "            # # Predict label\n",
        "            # y_pred = sess.run(prediction, feed_dict={images: [im]})[0]\n",
        "            # # Compute the vanilla mask and the smoothed mask.\n",
        "            # smoothgrad_mask_3d = gradient_saliency.GetSmoothedMask(im, stdev_spread=.05, nsamples=10, feed_dict={neuron_selector: y_pred})\n",
        "            # # Call the visualization methods to convert the 3D tensors to 2D grayscale.\n",
        "            # smoothgrad_mask_grayscale = saliency.tf1.VisualizeImageGrayscale(smoothgrad_mask_3d)\n",
        "            \n",
        "            smoothgrad_mask_grayscale = run_model(image, prediction, stdev_spread=.05, nsamples=10)\n",
        "\n",
        "            # Plot and save images\n",
        "            # cm = plt.get_cmap('inferno')\n",
        "            # colored_heatmap = cm(smoothgrad_mask_grayscale)  # RGBA (A contains colormap) -> convert o RGB via rgba2rgb\n",
        "            # image_overlay = 0.5 * (image/255) + 0.5 * rgba2rgb(colored_heatmap)  # img1*alpha + img2*(1-alpha)\n",
        "            # plt.imsave(os.path.normpath(os.path.join(heatmap_dir + selected_images[i])), image)\n",
        "            # plt.imsave(os.path.normpath(os.path.join(heatmap_dir + selected_images[i][:-5] + '_heatmap' + selected_images[i][-5:])), image_overlay)\n",
        "\n",
        "            path_image = os.path.normpath(os.path.join(heatmap_dir + selected_images[i]))\n",
        "            save_image(image, path_image)\n",
        "\n",
        "            path_heatmap = os.path.normpath(os.path.join(heatmap_dir + selected_images[i][:-5] + '_heatmap' + selected_images[i][-5:]))\n",
        "            export_heatmap(image, path_heatmap)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQFiCyMO2t7Z",
        "outputId": "09b49e19-dd77-4959-84f3-4ae2caa0f465"
      },
      "outputs": [],
      "source": [
        "print(dir(saliency))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhMMg3l9uu-K"
      },
      "source": [
        "# New section"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "simple_test_SECA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
