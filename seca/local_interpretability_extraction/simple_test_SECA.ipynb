{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-ncfL2BroQW",
        "outputId": "a76cae5b-6bde-4071-9138-44854a7bbb3a"
      },
      "outputs": [],
      "source": [
        "# !pip install saliency\n",
        "# !pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZJmYnLuzeN-",
        "outputId": "58898a12-9980-45f7-a46a-f062b5a0c23d"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive._mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjHbls0brHVX"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from keras.applications.inception_v3 import preprocess_input as inception_preproc\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.color import rgba2rgb\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import saliency\n",
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow.python.keras.backend as K\n",
        "# tf.disable_v2_behavior()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V__zMoNU16Qu",
        "outputId": "b1a26580-fbcd-4b04-b3ad-6970836c4b35"
      },
      "outputs": [],
      "source": [
        "# !pip list -v | grep saliency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxzSyLcZ3rpH"
      },
      "outputs": [],
      "source": [
        "from seca.utils import load_image, save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_model(graph, weights: str = \"imagenet\"):\n",
        "    \"\"\"[summary]\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    graph : [type]\n",
        "        [description]\n",
        "    weights : [type], optional\n",
        "        [description], by default \"imagenet\"\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    [type]\n",
        "        [description]\n",
        "    \"\"\"\n",
        "\n",
        "    model = InceptionV3(weights=weights)\n",
        "    logits = graph.get_tensor_by_name('predictions/Softmax:0')\n",
        "    neuron_selector = tf.placeholder(tf.int32)  # Used to select the logit of the prediction\n",
        "    y = logits[0][neuron_selector]  # logit of prediction\n",
        "    prediction = tf.argmax(logits, 1)\n",
        "    images = graph.get_tensor_by_name('input_1:0') \n",
        "\n",
        "    return model, y, neuron_selector, prediction, images\n",
        "\n",
        "\n",
        "def verify_images(path_images: str):\n",
        "    \"\"\"Verify images in dataset\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path_images : str\n",
        "        directory with images dataset\n",
        "    \"\"\"\n",
        "    # TODO: Check file extensions\n",
        "    # TODO: Check file size > 0\n",
        "\n",
        "    # Print image names\n",
        "    print(([name for name in os.listdir(path_images)]))\n",
        "\n",
        "\n",
        "def upload_data_to_model(path_images: str, sample_size: int = None, target_size: tuple = (299, 299), batch_size: int = 1):\n",
        "    \"\"\"[summary]\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path_images : [type]\n",
        "        [description]\n",
        "    sample_size : [type], optional\n",
        "        [description], by default None\n",
        "    target_size : [type], optional\n",
        "        [description], by default (299, 299)\n",
        "    batch_size : [type], optional\n",
        "        [description], by default 1\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    selected_images : list[str]\n",
        "        List of selected image paths\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    ValueError\n",
        "        [description]\n",
        "    ValueError\n",
        "        [description]\n",
        "    \"\"\"\n",
        "    \n",
        "    test_datagen = ImageDataGenerator(preprocessing_function=inception_preproc)\n",
        "    test_generator = test_datagen.flow_from_directory(path_images, target_size=target_size, batch_size=batch_size, class_mode='categorical', shuffle=False)\n",
        "    \n",
        "    # Select random sample if num_of_images is smaller than dataset\n",
        "    num_images = len(test_generator.filenames) if not sample_size else sample_size\n",
        "\n",
        "    if num_images > len(test_generator.filenames):\n",
        "        print(len(test_generator.filenames))\n",
        "        raise ValueError('The number of annotations cannot be higher than the number of available images.')\n",
        "    elif num_images == 0:\n",
        "        raise ValueError('The number of annotations needs to be greater than zero.')\n",
        "    \n",
        "    image_selection = np.random.choice(len(test_generator.filenames), num_images)\n",
        "    selected_images = np.array(test_generator.filenames)[image_selection]\n",
        "    \n",
        "    return selected_images\n",
        "\n",
        "\n",
        "def create_output_folder(path: str):\n",
        "    \"\"\"[summary]\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path_output : str\n",
        "        [description]\n",
        "    image_name : str\n",
        "        [description]\n",
        "    \"\"\"\n",
        "        \n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    \n",
        "\n",
        "def export_heatmap(image, smoothgrad_mask_grayscale, path_save: str, colormap: str = \"inferno\"):\n",
        "    \"\"\"[summary]\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : [type]\n",
        "        [description]\n",
        "    path_image : [type]\n",
        "        [description]\n",
        "    colormap : [type], optional\n",
        "        [description], by default \"inferno\"\n",
        "    \"\"\"\n",
        "\n",
        "    cm = plt.get_cmap(colormap)\n",
        "    colored_heatmap = cm(smoothgrad_mask_grayscale)  # RGBA (A contains colormap) -> convert o RGB via rgba2rgb\n",
        "    image_overlay = 0.5 * (image/255) + 0.5 * rgba2rgb(colored_heatmap)  # img1*alpha + img2*(1-alpha)\n",
        "    plt.imsave(path_save, image_overlay)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure proper handling of https requests\n",
        "# Issue and solution are described here: https://github.com/tensorflow/tensorflow/issues/33285\n",
        "\n",
        "import requests\n",
        "requests.packages.urllib3.disable_warnings()\n",
        "import ssl\n",
        "\n",
        "try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    # Legacy Python that doesn't verify HTTPS certificates by default\n",
        "    pass\n",
        "else:\n",
        "    # Handle target environment that doesn't support HTTPS verification\n",
        "    ssl._create_default_https_context = _create_unverified_https_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set parameters\n",
        "\n",
        "path_images = \"../example_data copy/test\"\n",
        "path_output = \"../../output\"\n",
        "num_of_images = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrtf-96osiLX",
        "outputId": "9025a385-018d-4618-dc37-48134632eab4"
      },
      "outputs": [],
      "source": [
        "# Initialize session\n",
        "sess = K.get_session()\n",
        "graph = sess.graph\n",
        "\n",
        "# Check dataset\n",
        "# verify_images(path_images)\n",
        "selected_images = upload_data_to_model(path_images, num_of_images)\n",
        "\n",
        "with graph.as_default():  # registers graph as default graph. Operations will be added to the graph\n",
        "            \n",
        "    model, y, neuron_selector, prediction, images = setup_model(graph, weights='imagenet')\n",
        "\n",
        "    # Construct the saliency object.\n",
        "    gradient_saliency = saliency.tf1.GradientSaliency(graph, sess, y, images)\n",
        "    \n",
        "    for img in tqdm(selected_images):\n",
        "        \n",
        "        path_image = Path(img)\n",
        "\n",
        "        # Create the folder   \n",
        "        output_folder = os.path.join(path_output, path_image.parents[0])\n",
        "        create_output_folder(output_folder)\n",
        "\n",
        "        # Skip if heatmap is already extracted\n",
        "        path_export_heatmap = os.path.join(output_folder, f'{path_image.stem}_heatmap.jpg' )\n",
        "        if not path_export_heatmap:\n",
        "            continue\n",
        "\n",
        "        # Load image\n",
        "        image = load_image(os.path.join(path_images, path_image))\n",
        "        im = inception_preproc(image)\n",
        "\n",
        "        # Predict label\n",
        "        y_pred = sess.run(prediction, feed_dict={images: [im]})[0]\n",
        "\n",
        "        # Compute the vanilla mask and the smoothed mask.\n",
        "        smoothgrad_mask_3d = gradient_saliency.GetSmoothedMask(im, stdev_spread=.05, nsamples=10, feed_dict={neuron_selector: y_pred})\n",
        "\n",
        "        # Call the visualization methods to convert the 3D tensors to 2D grayscale.\n",
        "        smoothgrad_mask_grayscale = saliency.tf1.VisualizeImageGrayscale(smoothgrad_mask_3d)        \n",
        "\n",
        "        # Save images and heatmaps\n",
        "        save_image(image, output_folder, path_image.name)\n",
        "        export_heatmap(image, smoothgrad_mask_grayscale, path_export_heatmap)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "simple_test_SECA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
